{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katearb/Data-Science-Notebooks/blob/master/2_Vector_Representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2Or-DVf1XTd"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfbOr2F3Q0Di"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import resample\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from gensim import utils, models\n",
        "import gensim.parsing.preprocessing as gsp\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "GV2DfFCQ23kt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnxJ7czFQ9Y4"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/katearb/files/main/jigsaw-toxic-comment-train.csv/jigsaw-toxic-comment-train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM4vHt7LWHKf",
        "outputId": "0bedbb88-8d5c-4817-e06a-f9d627a76512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    202165\n",
              "1     21384\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data['toxic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWYuDOs6KpwC"
      },
      "outputs": [],
      "source": [
        "# downsampling\n",
        "false_downsample = resample(data[data['toxic'] == 0],\n",
        "             replace=True,\n",
        "             n_samples=len(data[data['toxic'] == 1]) * 2,\n",
        "             random_state=42)\n",
        "\n",
        "data = false_downsample.append(data[data['toxic'] == 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5_SreIrTdxP"
      },
      "outputs": [],
      "source": [
        "# select required columns\n",
        "data = data[['comment_text', 'toxic']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrOHwHcSmbGB",
        "outputId": "89a8febe-8236-4f0e-c48d-1a3debfefa39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64152, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "d09aEC6mTe4K",
        "outputId": "05ee86db-45f0-4295-cb29-6fd589f70ed5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e60ccf41-e55b-4bb4-91e7-899c2385d2fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134944</th>\n",
              "      <td>\"\\n\\n  \\n\\nYour request to be unblocked has be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162417</th>\n",
              "      <td>::on that cell - it appears that it made it fr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145873</th>\n",
              "      <td>\"\\n Your submission at Articles for creation \\...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114692</th>\n",
              "      <td>Maybe something more like ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132623</th>\n",
              "      <td>United Kingdom Location\\nA British company bas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121978</th>\n",
              "      <td>\"While we can debate all day on whether the no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60771</th>\n",
              "      <td>Please also see: wp:CLAIM. —AsteriskSplat→</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151880</th>\n",
              "      <td>\"\\n\\nDohn, see my reply to Powers about Google...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186048</th>\n",
              "      <td>\", 7 September 2012 (UTC) \\n :::That's good ) ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96821</th>\n",
              "      <td>\"\\n\\n  \\n\\nYour request to be unblocked has be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e60ccf41-e55b-4bb4-91e7-899c2385d2fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e60ccf41-e55b-4bb4-91e7-899c2385d2fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e60ccf41-e55b-4bb4-91e7-899c2385d2fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             comment_text  toxic\n",
              "134944  \"\\n\\n  \\n\\nYour request to be unblocked has be...      0\n",
              "162417  ::on that cell - it appears that it made it fr...      0\n",
              "145873  \"\\n Your submission at Articles for creation \\...      0\n",
              "114692                        Maybe something more like ?      0\n",
              "132623  United Kingdom Location\\nA British company bas...      0\n",
              "121978  \"While we can debate all day on whether the no...      0\n",
              "60771          Please also see: wp:CLAIM. —AsteriskSplat→      0\n",
              "151880  \"\\n\\nDohn, see my reply to Powers about Google...      0\n",
              "186048  \", 7 September 2012 (UTC) \\n :::That's good ) ...      0\n",
              "96821   \"\\n\\n  \\n\\nYour request to be unblocked has be...      0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEFDSIlNegmV"
      },
      "source": [
        "### Data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syMJEyEXejsf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['comment_text'], data['toxic'], \n",
        "                                                    test_size=0.2, stratify=data['toxic'], \n",
        "                                                    random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byp1UupqWNQ8"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77x1t2UdWQpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37676c6-4713-4b2b-baa4-032037613b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        }
      ],
      "source": [
        "class Cleaner(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, filters):\n",
        "    self.filters = filters\n",
        "\n",
        "  def fit(self, X: pd.Series):\n",
        "    return self\n",
        "\n",
        "  def _transform_doc(self, s: str):\n",
        "    s = str(s).lower() # lower case for all words\n",
        "    s = utils.to_unicode(s)\n",
        "    for f in self.filters:\n",
        "        s = f(s)\n",
        "    return s\n",
        "\n",
        "  def transform(self, X: pd.Series()):\n",
        "\n",
        "    clean_X = [self._transform_doc(doc) for doc in tqdm(X)]\n",
        "    return pd.Series(clean_X)\n",
        "\n",
        "\n",
        "class Word2Vec(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def fit(self, X: pd.Series()):\n",
        "      return self\n",
        "\n",
        "  def _transform_doc(self, doc):\n",
        "    temp = pd.DataFrame()\n",
        "    for word in doc.split(' '):\n",
        "      try:\n",
        "        word_vec = word2vec[word]\n",
        "        temp = temp.append(pd.Series(word_vec), ignore_index=True)\n",
        "      except:\n",
        "        pass\n",
        "    return temp.mean() \n",
        "\n",
        "\n",
        "  def transform(self, X: pd.Series()):\n",
        "\n",
        "    data_vectors = [self._transform_doc(doc)  for doc in tqdm(X)] \n",
        "\n",
        "    return data_vectors\n",
        "\n",
        "\n",
        "def finetune_logreg(X_train_vectors, y_train, parameters):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "  random_search = RandomizedSearchCV(LogisticRegression(), parameters, n_jobs=-1, verbose=3, \n",
        "                                     scoring=['roc_auc'],\n",
        "                                     cv=cv, n_iter=10, refit='roc_auc')\n",
        "\n",
        "  random_search.fit(X_train_vectors, y_train)\n",
        "  return random_search.best_estimator_\n",
        "\n",
        "def calculate_roc_auc(y_true, y_pred_proba):\n",
        "  score = roc_auc_score(y_true, y_pred_proba)\n",
        "  print('ROC-AUC score:', score)\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpAy6yf7BgMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd43016-7db2-4c3a-cdfb-dc5ac41fc89c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "Bfa4_WDn-0EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation pipeline\n",
        "filters = [\n",
        "           gsp.strip_tags,  # remove tags \n",
        "           gsp.strip_punctuation,  # remove punctuation\n",
        "           gsp.strip_multiple_whitespaces,  # standarize the spaces \n",
        "           gsp.strip_numeric,\n",
        "           gsp.remove_stopwords,  # stopwords  \n",
        "           gsp.strip_short,  # delete words with len < 3\n",
        "           gsp.stem_text  # stemming \n",
        "          ]\n",
        "\n",
        "prep_pipeline = Pipeline(steps=[\n",
        "                                ('cleaner', Cleaner(filters)),\n",
        "                                ('vectorizer', TfidfVectorizer())\n",
        "                              ]\n",
        "                          )\n",
        "prep_pipeline.fit(X_train)"
      ],
      "metadata": {
        "id": "etg_rxQj_MJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data\n",
        "X_train_tfidf = prep_pipeline.transform(X_train)\n",
        "X_test_tfidf = prep_pipeline.transform(X_test)"
      ],
      "metadata": {
        "id": "ng301ZtWQWEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit log reg\n",
        "parameters = {\n",
        "    'penalty' : ['l1', 'l2'],\n",
        "    'C' : np.logspace(-4, 4, 10),\n",
        "    'solver' : ['liblinear'],\n",
        "}\n",
        "\n",
        "log_clf = finetune_logreg(X_train_tfidf, y_train, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbSxaGGEC4_L",
        "outputId": "75f8eed5-34fe-4246-82b8-846e3c4a3542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score the test dataset\n",
        "y_pred_proba = log_clf.predict_proba(X_test_tfidf)\n",
        "tfidf_rocauc = calculate_roc_auc(y_test, y_pred_proba[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-4SveL2DAPS",
        "outputId": "56533161-ca24-49bd-ebff-039b4f6173e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score: 0.9635949616921564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRAuHOBqdQuv"
      },
      "source": [
        "# Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et3rsOj3in4d"
      },
      "outputs": [],
      "source": [
        "!brew install wget\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfF1mCePiv01"
      },
      "outputs": [],
      "source": [
        "!gzip -d GoogleNews-vectors-negative300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAAYO999k5v0"
      },
      "outputs": [],
      "source": [
        "word2vec = models.KeyedVectors.load_word2vec_format(\n",
        "    '/content/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdpJQL0NZQxj"
      },
      "outputs": [],
      "source": [
        "# data preparation pipeline\n",
        "filters = [\n",
        "           gsp.strip_tags,  # remove tags \n",
        "           gsp.strip_punctuation,  # remove punctuation\n",
        "           gsp.strip_multiple_whitespaces,  # standarized the spaces \n",
        "           gsp.strip_numeric,\n",
        "           gsp.remove_stopwords,  # stop words  \n",
        "           gsp.strip_short,  # delete words with len < 3\n",
        "           gsp.stem_text  # stemming \n",
        "          ]\n",
        "\n",
        "prep_pipeline = Pipeline(steps=[\n",
        "                                ('cleaner', Cleaner(filters)),\n",
        "                                ('word2vec', Word2Vec())\n",
        "                              ]\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H9jHPlLluTI"
      },
      "outputs": [],
      "source": [
        "# vectorize and save train data\n",
        "\n",
        "# X_train_vectors = prep_pipeline.fit_transform(X_train)\n",
        "\n",
        "# nan_ids = X_train_vectors[X_train_vectors.isnull().any(1)].index\n",
        "# X_train_vectors = X_train_vectors[[i not in nan_ids for i in range(len(X_train_vectors))]]\n",
        "# y_train_w2v = y_train[[i not in nan_ids for i in range(len(y_train))]]\n",
        "\n",
        "# X_train_vectors.to_csv('/content/drive/MyDrive/embeds/word2vec_vectors_train')\n",
        "# y_train_w2v.to_csv('/content/drive/MyDrive/embeds/word2vec_y_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKOxIvJtS4cV"
      },
      "outputs": [],
      "source": [
        "# load train data\n",
        "X_train_vectors = pd.read_csv('/content/drive/MyDrive/embeds/word2vec_vectors_train', index_col=0)\n",
        "y_train_w2v = pd.read_csv('/content/drive/MyDrive/embeds/word2vec_y_train', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVx3qNXAM9WA"
      },
      "outputs": [],
      "source": [
        "# vectorize and save test data\n",
        "\n",
        "# X_test_vectors = prep_pipeline.fit_transform(X_test)\n",
        "\n",
        "# nan_ids = X_test_vectors[X_test_vectors.isnull().any(1)].index\n",
        "# X_test_vectors = X_test_vectors[[i not in nan_ids for i in range(len(X_test_vectors))]]\n",
        "# y_test_w2v = y_test[[i not in nan_ids for i in range(len(y_test))]]\n",
        "\n",
        "# X_test_vectors.to_csv('/content/drive/MyDrive/embeds/word2vec_vectors_test')\n",
        "# y_test_w2v.to_csv('/content/drive/MyDrive/embeds/word2vec_y_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmlAQoBzXhPi"
      },
      "outputs": [],
      "source": [
        "# load test data\n",
        "X_test_vectors = pd.read_csv('/content/drive/MyDrive/embeds/word2vec_vectors_test', index_col=0)\n",
        "y_test_w2v = pd.read_csv('/content/drive/MyDrive/embeds/word2vec_y_test', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6j4Dyjug23o"
      },
      "outputs": [],
      "source": [
        "# fit log reg\n",
        "\n",
        "parameters = {\n",
        "    'penalty' : ['l1', 'l2'],\n",
        "    'C' : np.logspace(-4, 4, 10),\n",
        "    'solver' : ['liblinear'],\n",
        "}\n",
        "\n",
        "log_clf = finetune_logreg(X_train_vectors, y_train_w2v, parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ro045a7ryvD",
        "outputId": "521a0308-3375-4a3e-8ebe-5e8473b06c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC score: 0.9317629582827421\n"
          ]
        }
      ],
      "source": [
        "# score the test dataset\n",
        "y_pred_proba = log_clf.predict_proba(X_test_vectors)\n",
        "word2vec_rocauc = calculate_roc_auc(y_test_w2v, y_pred_proba[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyxYmWwEzuz3"
      },
      "source": [
        "# Fine-tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_bert(val_loader, net, criterion):\n",
        "  print('**Validation**')\n",
        "  total_acc_val = 0\n",
        "  total_loss_val = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for seq, attn_masks, labels in tqdm(val_loader):\n",
        "      labels = labels.float()\n",
        "      seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "      output = net(seq, attn_masks).squeeze(1)\n",
        "\n",
        "      batch_loss = criterion(output, labels)\n",
        "      total_loss_val += batch_loss.item()\n",
        "      output_round = torch.tensor([[*map(lambda x: round(float(x)), pred)] for pred in output])\n",
        "      acc = (output_round.to(device) == labels).sum().item()\n",
        "      total_acc_val += acc\n",
        "    \n",
        "  return total_acc_val, total_loss_val\n",
        "\n",
        "def train_bert(net, criterion, opti, train_loader, val_loader, epochs, path):\n",
        "    net = net.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "    for ep in range(epochs):\n",
        "      total_acc_train = 0\n",
        "      total_loss_train = 0\n",
        "      print(f'**Epoch {ep}**')\n",
        "      with torch.enable_grad():        \n",
        "        for seq, attn_masks, labels in tqdm(train_loader):\n",
        "          opti.zero_grad()  \n",
        "\n",
        "          seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
        "\n",
        "          output = net(seq, attn_masks).squeeze(1)\n",
        "\n",
        "          loss = criterion(output, labels)\n",
        "          total_loss_train += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "          opti.step()\n",
        "\n",
        "          output_round = torch.tensor([[*map(lambda x: round(float(x)), pred)] for pred in output])\n",
        "          acc = (output_round.to(device) == labels).sum().item()\n",
        "          total_acc_train += acc\n",
        "\n",
        "      total_acc_val, total_loss_val = validate_bert(val_loader, net, criterion)\n",
        "      torch.save(net.state_dict(), f'{path}epoch{ep}')\n",
        "      print(\n",
        "        f'Epochs: {epochs + 1} | Train Loss: {total_loss_train / len(train_loader): .3f} \\\n",
        "        | Train Accuracy: {total_acc_train / len(train_loader) * 2: .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(val_loader): .3f} \\\n",
        "        | Val Accuracy: {total_acc_val / len(val_loader) * 2: .3f}')\n",
        "      \n",
        "\n",
        "def test_bert(net, test_loader):\n",
        "  pred, true = [], []\n",
        "  with torch.no_grad():\n",
        "    for seq, attn_masks, labels in tqdm(test_loader):\n",
        "      seq, attn_masks = seq.to(device), attn_masks.to(device)\n",
        "      output = net(seq, attn_masks).squeeze(1)\n",
        "      true.append(float(labels[0]))\n",
        "      pred.append(float(output[0][1]))\n",
        "  return calculate_roc_auc(true, pred)"
      ],
      "metadata": {
        "id": "s8bnqDzPe4Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, X, y=None, maxlen=512):\n",
        "\n",
        "        self.X = list(X)\n",
        "        self.y = list(y) if y is not None else None\n",
        "\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        sentence = self.X[index]\n",
        "        label = self.y[index] if self.y is not None else None\n",
        "\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) \n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, torch.tensor(label)\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert=True):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "        \n",
        "        self.fc1 = nn.Linear(768, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc3 = nn.Linear(10, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        _, x =  self.bert_layer(input_ids=seq, attention_mask=attn_masks, \n",
        "                                      return_dict=False)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return self.sigmoid(x)"
      ],
      "metadata": {
        "id": "AsRPdvrM3BqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiGfl3xK16p_"
      },
      "outputs": [],
      "source": [
        "# define cleaner\n",
        "filters = [\n",
        "           gsp.strip_tags,  # remove tags \n",
        "           gsp.strip_punctuation,  # remove punctuation\n",
        "           gsp.strip_multiple_whitespaces,  # standarized the spaces \n",
        "           gsp.strip_numeric,\n",
        "           gsp.remove_stopwords,  # stop words\n",
        "          ]\n",
        "cleaner = Cleaner(filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhQtKzmQm-Fw",
        "outputId": "ad57a5b3-bef6-412e-828b-b5fa8beb2c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46188/46188 [00:03<00:00, 14300.37it/s]\n",
            "100%|██████████| 5133/5133 [00:00<00:00, 14701.20it/s]\n",
            "100%|██████████| 12831/12831 [00:00<00:00, 13672.04it/s]\n"
          ]
        }
      ],
      "source": [
        "# prepare data\n",
        "y_train_bert = [[0., 1.] if label == 1 else [1., 0.] for label in y_train]\n",
        "X_train_bert, X_val_bert, y_train_bert, y_val_bert = train_test_split(X_train, y_train_bert, \n",
        "                                                    test_size=0.1, stratify=y_train_bert, \n",
        "                                                    random_state=42)\n",
        "\n",
        "X_train_bert = cleaner.fit_transform(X_train_bert)\n",
        "X_val_bert = cleaner.fit_transform(X_val_bert)\n",
        "X_test_bert = cleaner.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create loaders\n",
        "train_set = BertDataset(X_train_bert, y_train_bert, maxlen=256)\n",
        "val_set = BertDataset(X_val_bert, y_val_bert, maxlen=256)\n",
        "test_set = BertDataset(X_test_bert,  y_test, maxlen=256)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=8, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=8, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=1, num_workers=2)"
      ],
      "metadata": {
        "id": "jR6tyXN13QLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model, opimizer, criterion\n",
        "bert_clf = BertClassifier(freeze_bert=True)\n",
        "criterion = nn.BCELoss()\n",
        "opti = optim.Adam(bert_clf.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "SXvuFdn43lxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f55a7ed-8436-4890-82a7-b41d7518af65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load trained model\n",
        "# bert_clf.load_state_dict(torch.load(r'/content/drive/MyDrive/bert_classifier/epoch1'))\n",
        "# bert_clf.to(device)\n",
        "# bert_clf.eval()"
      ],
      "metadata": {
        "id": "quBK5Kca5NXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train bert_clf\n",
        "train_bert(bert_clf, criterion, opti, train_loader, val_loader, 2, '/content/drive/MyDrive/bert_classifier/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVjvcNslKBXp",
        "outputId": "b95e8e00-12a5-4173-eb50-449ad60b49b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Epoch 0**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5774/5774 [12:15<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 642/642 [01:21<00:00,  7.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.337         | Train Accuracy:  27.330         | Val Loss:  0.345         | Val Accuracy:  27.293\n",
            "**Epoch 1**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5774/5774 [12:15<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 642/642 [01:21<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.329         | Train Accuracy:  27.468         | Val Loss:  0.340         | Val Accuracy:  27.305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test bert_clf\n",
        "bert_rocauc = test_bert(bert_clf, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H94sOHqDryCQ",
        "outputId": "4400a3a6-d60f-48af-a3fa-cc907b3784bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12831/12831 [04:20<00:00, 49.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score: 0.9255199292571382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tLyCX9qpCkj"
      },
      "source": [
        "# FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTBo74fErChx"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext"
      ],
      "metadata": {
        "id": "ZKHqsc5yEkJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdEhZcIwrr2X"
      },
      "outputs": [],
      "source": [
        "def test_fasttext(model, X_test_ft, y_test):\n",
        "  preds = model.predict(list(X_test_ft))\n",
        "  preds_proba = [score if '1' in label[0] else 1 - score for label, score in zip(preds[0], preds[1])]\n",
        "  return calculate_roc_auc(y_test, preds_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0ACc08NqnJ9"
      },
      "outputs": [],
      "source": [
        "# define cleaner\n",
        "filters = [\n",
        "           gsp.strip_tags,  # remove tags \n",
        "           gsp.strip_punctuation,  # remove punctuation\n",
        "           gsp.strip_multiple_whitespaces,  # standarized the spaces \n",
        "           gsp.strip_numeric,\n",
        "           gsp.remove_stopwords,  # stop words  \n",
        "           gsp.strip_short,  # delete words with len < 3\n",
        "          ]\n",
        "cleaner = Cleaner(filters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data\n",
        "X_train_ft = cleaner.fit_transform(X_train)\n",
        "X_test_ft = cleaner.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "am2zkggpQ_sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create file with data\n",
        "with open('ft_data_train', 'w') as f:\n",
        "  f.write('\\n'.join([f'__label__{label} {text}' for text, label in zip(X_train_ft, y_train)]))"
      ],
      "metadata": {
        "id": "j7AB4oINmxCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiU0qDMupD-2"
      },
      "outputs": [],
      "source": [
        "# define and train fasttext model\n",
        "fasttext_model = fasttext.train_supervised(input='ft_data_train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test fasttext model\n",
        "fasttext_roc_auc = test_fasttext(fasttext_model, X_test_ft, y_test)"
      ],
      "metadata": {
        "id": "UrR-cKdOncD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de56a65-dd06-488f-c362-8e8de3e85710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score: 0.9553688927442155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment analysis with textBlob"
      ],
      "metadata": {
        "id": "1VtFXb-ySBox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "Q6daCdFrSExs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def textblob_sentiment(X, threshold):\n",
        "  y_pred, y_proba0, y_proba1, y_proba = [], [], [], []\n",
        "  for text in list(X):\n",
        "    testimonial = TextBlob(text)\n",
        "    pol = testimonial.sentiment.polarity\n",
        "    if pol > threshold:\n",
        "      y_pred.append(1)\n",
        "      y_proba1.append([1 - pol / (2), pol / (2)])\n",
        "      y_proba.append(y_proba1[-1])\n",
        "    else:\n",
        "      y_pred.append(0)\n",
        "      y_proba0.append([pol / (-2), 1 - pol / (-2)])\n",
        "      y_proba.append(y_proba0[-1])\n",
        "\n",
        "  return np.array(y_pred), np.array(y_proba)\n",
        "\n",
        "def evaluate_textblob(X, y, t=0):\n",
        "  y_pred, y_proba = textblob_sentiment(X, t)\n",
        "  rocauc = roc_auc_score(y, y_proba[:, 1])\n",
        "  print('ROC-AUC score', rocauc)\n",
        "  return rocauc"
      ],
      "metadata": {
        "id": "eC4M2GnXSQ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblob_rocauc = evaluate_textblob(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywB516RbShu9",
        "outputId": "3708aba7-9469-4f6e-8555-6412f639012a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score 0.5752705214186468\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5752705214186468"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XEP3PecdIDO"
      },
      "source": [
        "# BP-embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb"
      ],
      "metadata": {
        "id": "JoAKp1cDVX_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adc7fc1-84de-4b37-8de3-b238404495ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2021.10.8)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.3 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4I4JcostVTE"
      },
      "outputs": [],
      "source": [
        "from bpemb import BPEmb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_bpemb(val_loader, net, criterion):\n",
        "  print('**Validation**')\n",
        "  total_acc_val, total_loss_val = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for texts, labels in tqdm(val_loader):\n",
        "      labels = torch.tensor(labels.float()).to(device)\n",
        "\n",
        "      output = net(texts)\n",
        "\n",
        "      batch_loss = criterion(output, labels)\n",
        "      total_loss_val += batch_loss.item()\n",
        "\n",
        "      output_round = torch.tensor([[*map(lambda x: round(float(x)), pred)] for pred in output])\n",
        "      acc = (output_round.to(device) == labels).sum().item()\n",
        "      total_acc_val += acc\n",
        "    \n",
        "  return total_acc_val, total_loss_val\n",
        "\n",
        "def train_bpemb(net, criterion, opti, train_loader, val_loader, epochs, path):\n",
        "    net = net.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "    for ep in range(epochs):\n",
        "      total_acc_train, total_loss_train = 0, 0\n",
        "      print(f'**Epoch {ep}**')\n",
        "      with torch.enable_grad():        \n",
        "        for texts, labels in tqdm(train_loader):\n",
        "          opti.zero_grad()  \n",
        "\n",
        "          labels = torch.tensor(labels.float()).to(device)\n",
        "\n",
        "          output = net(texts)\n",
        "\n",
        "          loss = criterion(output, labels)\n",
        "          total_loss_train += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "          opti.step()\n",
        "\n",
        "          output_round = torch.tensor([[*map(lambda x: round(float(x)), pred)] for pred in output])\n",
        "          acc = (output_round.to(device) == labels).sum().item()\n",
        "          total_acc_train += acc\n",
        "\n",
        "      total_acc_val, total_loss_val = validate_bpemb(val_loader, net, criterion)\n",
        "      torch.save(net.state_dict(), f'{path}epoch{ep}')\n",
        "      print(\n",
        "        f'Epochs: {epochs + 1} | Train Loss: {total_loss_train / len(train_loader): .3f} \\\n",
        "        | Train Accuracy: {total_acc_train / len(train_loader) * 2: .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(val_loader): .3f} \\\n",
        "        | Val Accuracy: {total_acc_val / len(val_loader) * 2: .3f}')\n",
        "      \n",
        "\n",
        "def test_bpemb(net, test_loader):\n",
        "  pred, true = [], []\n",
        "  with torch.no_grad():\n",
        "    for texts, labels in tqdm(test_loader):\n",
        "      labels = torch.tensor(labels.float()).to(device)\n",
        "      output = net(texts)\n",
        "      true.append(float(labels[0]))\n",
        "      pred.append(float(output[0][1]))\n",
        "  return calculate_roc_auc(true, pred)"
      ],
      "metadata": {
        "id": "Xp5buhb7H9yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBUiUgcPex9R"
      },
      "outputs": [],
      "source": [
        "class BPEmbDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.texts = list(X)\n",
        "    self.labels = list(y)\n",
        "\n",
        "  def classes(self):\n",
        "    return self.labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def get_batch_labels(self, idx):\n",
        "    # Fetch a batch of labels\n",
        "    return np.array(self.labels[idx])\n",
        "\n",
        "  def get_batch_texts(self, idx):\n",
        "    # Fetch a batch of input\n",
        "    return self.texts[idx]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_texts = self.get_batch_texts(idx)\n",
        "    batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "    return batch_texts, batch_y\n",
        "\n",
        "\n",
        "class BPEmbClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BPEmbClassifier, self).__init__()\n",
        "\n",
        "        self.bpemb_en = BPEmb(lang=\"en\", dim=300)\n",
        "        self.fc1 = nn.Linear(300, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc3 = nn.Linear(10, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, input):\n",
        "        x = torch.Tensor([np.average(self.bpemb_en.embed(text), axis=0).reshape(300,1) for text in input]).squeeze(-1).to(device)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return self.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF-m6ZQbmcY3"
      },
      "outputs": [],
      "source": [
        "# define cleaner\n",
        "def drop_empty(X):\n",
        "  return [text for text in X if len(text) != 0]\n",
        "\n",
        "filters = [\n",
        "           gsp.strip_tags,  # remove tags \n",
        "           gsp.strip_punctuation,  # remove punctuation\n",
        "           gsp.strip_multiple_whitespaces,  # standarized the spaces \n",
        "           gsp.strip_numeric,\n",
        "           gsp.remove_stopwords,  # stop words  \n",
        "           gsp.stem_text  # stemming \n",
        "          ]\n",
        "\n",
        "cleaner = Cleaner(filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPiBXEn_m2Pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9d8865-c76c-45a6-ec7d-629d42254c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 41056/41056 [00:11<00:00, 3444.22it/s]\n",
            "100%|██████████| 10265/10265 [00:02<00:00, 3529.89it/s]\n",
            "100%|██████████| 12831/12831 [00:03<00:00, 3308.94it/s]\n"
          ]
        }
      ],
      "source": [
        "# prepare data\n",
        "y_train_bpemb = [[0., 1.] if label == 1 else [1., 0.] for label in y_train]\n",
        "X_train_bpemb, X_val_bpemb, y_train_bpemb, y_val_bpemb = train_test_split(X_train, y_train_bpemb, \n",
        "                                                            test_size=0.2, stratify=y_train_bpemb, \n",
        "                                                            random_state=42)\n",
        "\n",
        "X_train_bpemb = drop_empty(cleaner.fit_transform(X_train_bpemb))\n",
        "X_val_bpemb = drop_empty(cleaner.fit_transform(X_val_bpemb))\n",
        "X_test_bpemb = drop_empty(cleaner.fit_transform(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVPc86Qancor"
      },
      "outputs": [],
      "source": [
        "# define loaders\n",
        "train_bpemb_set = BPEmbDataset(X_train_bpemb, y_train_bpemb)\n",
        "val_bpemb_set = BPEmbDataset(X_val_bpemb, y_val_bpemb)\n",
        "test_bpemb_set = BPEmbDataset(X_test_bpemb, y_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_bpemb_set, batch_size=8)\n",
        "val_loader = torch.utils.data.DataLoader(val_bpemb_set, batch_size=8)\n",
        "test_loader = torch.utils.data.DataLoader(test_bpemb_set, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c5hcMTZnrGM"
      },
      "outputs": [],
      "source": [
        "# define model, optimizer, criterion\n",
        "EPOCHS = 10\n",
        "bpemb_clf = BPEmbClassifier().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "opti = optim.Adam(bpemb_clf.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9JTCjwann4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253d2009-d919-47e5-e575-e59c7ad0600e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Epoch 0**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5129 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "100%|██████████| 5129/5129 [00:31<00:00, 164.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1282 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "100%|██████████| 1282/1282 [00:06<00:00, 208.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.638         | Train Accuracy:  21.306         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 1**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 164.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 206.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.329         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 2**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 164.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 205.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.328         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 3**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 163.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 204.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.329         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 4**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 164.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 204.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.330         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 5**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 163.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 208.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.330         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 6**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 163.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 208.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.330         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 7**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 163.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 204.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.330         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 8**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 163.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 202.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.330         | Val Loss:  0.637         | Val Accuracy:  21.329\n",
            "**Epoch 9**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5129/5129 [00:31<00:00, 162.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Validation**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1282/1282 [00:06<00:00, 201.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.637         | Train Accuracy:  21.330         | Val Loss:  0.637         | Val Accuracy:  21.329\n"
          ]
        }
      ],
      "source": [
        "# train bpemb_clf\n",
        "train_bpemb(bpemb_clf, criterion, opti, train_loader, val_loader, EPOCHS, '/content/drive/MyDrive/bpemd_classifier/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test bpemb_clf\n",
        "bp_rocauc = test_bpemb(bpemb_clf, test_loader)"
      ],
      "metadata": {
        "id": "yXwUiqmIKwiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6ab1ae-2385-4e7d-971c-944d11d93030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/12821 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "100%|██████████| 12821/12821 [00:13<00:00, 958.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison"
      ],
      "metadata": {
        "id": "lp2Qvw13jQbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [tfidf_rocauc, word2vec_rocauc, bert_rocauc, fasttext_roc_auc, textblob_rocauc, bp_rocauc]\n",
        "names = ['TF-IDF & Log-Reg', 'Word2vec & Log-Reg', 'Bert', 'FastTexts', 'TextBlob (sentiment polarity)', 'BytePair-Embeddings']\n",
        "\n",
        "pd.DataFrame(results, index=names, columns=['ROC-AUC']).sort_values(by=['ROC-AUC'], ascending=False)"
      ],
      "metadata": {
        "id": "82OoglYuJ1H6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "bf7b5541-cb2c-4807-ceec-ce372aae2050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d267fdc-a181-4884-99ee-1a2b5c44ac6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROC-AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TF-IDF &amp; Log-Reg</th>\n",
              "      <td>0.963595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FastTexts</th>\n",
              "      <td>0.955369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2vec &amp; Log-Reg</th>\n",
              "      <td>0.931763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bert</th>\n",
              "      <td>0.925520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TextBlob (sentiment polarity)</th>\n",
              "      <td>0.575271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BytePair-Embeddings</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d267fdc-a181-4884-99ee-1a2b5c44ac6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d267fdc-a181-4884-99ee-1a2b5c44ac6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d267fdc-a181-4884-99ee-1a2b5c44ac6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                ROC-AUC\n",
              "TF-IDF & Log-Reg               0.963595\n",
              "FastTexts                      0.955369\n",
              "Word2vec & Log-Reg             0.931763\n",
              "Bert                           0.925520\n",
              "TextBlob (sentiment polarity)  0.575271\n",
              "BytePair-Embeddings            0.500000"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jrROgPN4f6jX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Bfa4_WDn-0EQ",
        "dRAuHOBqdQuv",
        "1tLyCX9qpCkj",
        "1VtFXb-ySBox"
      ],
      "name": "2_Vector_Representations.ipynb",
      "provenance": [],
      "mount_file_id": "1yLzW_4O_OTlLLfmgDhOZwPsjyobN7qik",
      "authorship_tag": "ABX9TyNrqrqNdwgm7WRXzs3JOtLv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}